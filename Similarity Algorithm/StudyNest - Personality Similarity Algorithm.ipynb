{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<br>\n",
    "\n",
    "![Imgur](http://i.imgur.com/UnPy2w0.png)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StudyNest      -      *Personality Similarity Algorithm*\n",
    "\n",
    "\n",
    "<br> \n",
    "\n",
    "- Applies the Rocchio and Cosine Similarity Algorithm\n",
    "\n",
    "\n",
    "\n",
    "- Uses the algorithm and trains a KNeighborsRegressor model to predict the centroid values in comparison the entire dataset by taking the mean of cosine similarity (Rocchio Algorithm)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "<br>\n",
    "\n",
    "- Pandas + Numpy for Data\n",
    "\n",
    "\n",
    "- Sklearn for algorithms and machine learning\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas for Dataframe/Data Cleaning\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy for arrays\n",
    "import numpy as np\n",
    "\n",
    "# Import Cosine_similarity for similarity algorithm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import K-Neighbors Regressor model for  prediction\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Import train_test_split for training and validation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cleaning Data\n",
    "\n",
    "<br>\n",
    "\n",
    "- Removing NA and Missing Values\n",
    "\n",
    "\n",
    "- Factorizing the Country Strings\n",
    "\n",
    "\n",
    "- Removing 'Source' and 'Elapsed' from the Dataset\n",
    "\n",
    "\n",
    "- Removing outlier values for Age and Accuracy\n",
    "\n",
    "\n",
    "- Normalizing the Dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the personality data\n",
    "personality = pd.read_csv('personality_data.csv')\n",
    "\n",
    "# Dropping the entire row if any value is missing or NA\n",
    "personality.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorizing the unique countries to numbers (e.g US is 0, NZ is 1, IT is 2, ...)\n",
    "labels, levels = pd.factorize(personality['country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the country strings\n",
    "label = []\n",
    "for i in personality['country']:\n",
    "    # Find the index where the name of the country is equal to the value in the dataframe\n",
    "    level = np.where(levels == i)\n",
    "    # Append that number to a list\n",
    "    label.append(level[0][0])\n",
    "    \n",
    "# Replace the column 'country' with the number labels of the countries\n",
    "personality['country'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Source and Elapsed Data Value (Doesn't help out the prediction)\n",
    "personality.drop(columns = ['source', 'elapsed'], inplace = True)\n",
    "\n",
    "# Dropping values of accuracy over 100. The max value of accuracy is 100 and min is 0. \n",
    "personality = personality[personality['accuracy'] <= 100]\n",
    "\n",
    "# Dropping values of age over 80. This is to maintain the validity of the age values.\n",
    "personality = personality[personality['age'] <= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the numerical data\n",
    "for i in personality.columns:\n",
    "    # finding the max value of each column\n",
    "    max = personality[i].max()\n",
    "    # Dividing every value in the column by the max\n",
    "    personality[i] = personality[i]/max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Applying Similarity Algorithm (Cosine Similarity)  + Rocchio Algorithm\n",
    "\n",
    "<br>\n",
    "\n",
    "- Applying Cosine Similarity\n",
    "\n",
    "\n",
    "- Includes the calculation of the centroid values of closeness in comparison to all the other values in the dataset (mean of cosine similarity) \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the cosine similarity to find the similarity between the first 10000 data values in the dataframe\n",
    "# There are 50000 rows of datavalues; however, due to time and computation restraints only 10000 values are used.\n",
    "cos_im = cosine_similarity(personality[:10000], personality[:10000]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the mean of the cosine similarity\n",
    "# The mean is the centroid value of closeness in comparison to all the other datavalues in the dataset\n",
    "cos_im = np.array(cos_im).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(personality.values[:10000], cos_im, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Searching\n",
    "\n",
    "<br>\n",
    "\n",
    "- For loop to find best n_neighbors for hyperparameter\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors hyperparameter =  2\n"
     ]
    }
   ],
   "source": [
    "# Defining n_search to store the scores for each model for n_neighbors from 1 to 20\n",
    "n_search = []\n",
    "\n",
    "# Try all n_neighbors from 1 to 20\n",
    "for i in range(1, 20):\n",
    "    # Define the Regression Model\n",
    "    knr = KNeighborsRegressor(n_neighbors = i) # Add weights in the features to increase each accuracy\n",
    "    # Training the model with the training data\n",
    "    knr.fit(X_train, y_train)\n",
    "    # Scoring the trained model\n",
    "    score = knr.score(X_test, y_test)\n",
    "    # Appending the scores to n_search\n",
    "    n_search.append(score)\n",
    "    \n",
    "# Apply numpy function argmax (add 1 because started searching at n_neighbors = 1) to find best hyperparameter\n",
    "best_n = np.array(n_search).argmax() + 1\n",
    "    \n",
    "print('Best n_neighbors hyperparameter = ', best_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and Testing the Model\n",
    "\n",
    "<br>\n",
    "\n",
    "- Use KNeighborsRegressor Model and n_neighbors = 2 hyperparameter for best results\n",
    "\n",
    "\n",
    "- Train the Model using training data\n",
    "\n",
    "\n",
    "- Predicting/Testing the centroid values in comparison to the data we used to train the model. Using this to compare the prediction with another prediction to see if the two personality types are similar.\n",
    "\n",
    "\n",
    "- Apply 10 percent similarity to see if X_test[0] is similar to X_test[1]\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Percentage =  3.092817085004196 %\n",
      "\n",
      "X_test[0] is similar to X_test[1]\n"
     ]
    }
   ],
   "source": [
    "# Defining the best score model with the best n_neighbors from the hyperparameter search\n",
    "knr = KNeighborsRegressor(n_neighbors = best_n) # Add weights in the features to increase each accuracy\n",
    "# Training the model with the training data\n",
    "knr.fit(X_train, y_train)\n",
    "# Predict first input data values (Personality A)\n",
    "preds_0 = knr.predict([X_test[0]])\n",
    "# Predict second input data values (Personality B)\n",
    "preds_1 = knr.predict([X_test[1]])\n",
    "\n",
    "# approx 10 Percent Similarity since all the centroid closeness values are in between 0.85 and 0.95\n",
    "# Similar if less than 0.01 because there aren't that many unusual/out of the ordinary personalities\n",
    "\n",
    "# The Difference in Closeness, which is how similar the two personalities are\n",
    "print('Similarity Percentage = ', abs(preds_0 - preds_1)[0] * 1000,'%\\n') # Times 1000 because values are in between 0.85 and 0.95\n",
    " \n",
    "\n",
    "\n",
    "# Determining if the two Personalities are Similar (If they are 10 Percent Similar)\n",
    "if abs(preds_0 - preds_1) < 0.01:\n",
    "    print('X_test[0] is similar to X_test[1]')\n",
    "else:\n",
    "    print('X_test[0] is not similar to X_test[1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the Model using the Test Set\n",
    "\n",
    "<br>\n",
    "\n",
    "- Calculating score using the best hyperparameter model \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8529519570839639"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring the test set\n",
    "knr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "____\n",
    "\n",
    "<br>\n",
    "\n",
    "Copyright &copy;. &nbsp; All Rights Reserved. &nbsp; _**StudyNest**_\n",
    "\n",
    "<br>\n",
    "\n",
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
